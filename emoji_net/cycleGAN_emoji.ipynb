{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import tensorflow.keras as keras\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import LeakyReLU, UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='data/'\n",
    "raw_data_dir=data_dir+'raw/'\n",
    "\n",
    "def get_img(i,target_size):\n",
    "    import imageio, skimage\n",
    "    x = imageio.imread(raw_data_dir+'data_'+str(i)+'_x.jpg',as_gray=True).astype(np.float)\n",
    "    x = scipy.misc.imresize(x, target_size)\n",
    "    x= np.stack((x,)*1, -1)\n",
    "    x = x/127.5 - 1.\n",
    "    \n",
    "    y = imageio.imread(raw_data_dir+'data_'+str(i)+'_y.jpg', as_gray=True).astype(np.float)\n",
    "    y = scipy.misc.imresize(y, target_size)\n",
    "    y= np.stack((y,)*1, -1)\n",
    "    y = y/127.5 - 1.\n",
    "\n",
    "    return x,y\n",
    "\n",
    "def load_images(target_size):\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    img_files = [f for f in listdir(raw_data_dir) if isfile(join(raw_data_dir, f)) and '_x.jpg' in f]\n",
    "    n_x=len(img_files)\n",
    "    X=np.zeros((n_x,target_size[0], target_size[1], target_size[2]))\n",
    "    Y=np.zeros((n_x,target_size[0], target_size[1], target_size[2]))\n",
    "    \n",
    "    for i in range(n_x):\n",
    "        x,y =get_img(i,target_size)\n",
    "        X[i,:,:,:] = x\n",
    "        Y[i,:,:,:] = y\n",
    "    return X,Y,n_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE https://github.com/eriklindernoren/Keras-GAN\n",
    "\n",
    "def build_generator(input_shape,gf,name):\n",
    "    \"\"\"U-Net Generator\"\"\"\n",
    "    \n",
    "    n_H, n_W, n_C = input_shape\n",
    "    def conv2d(layer_input, filters, f_size=4):\n",
    "        \"\"\"Layers used during downsampling\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        d = InstanceNormalization()(d)\n",
    "        return d\n",
    "\n",
    "    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "        \"\"\"Layers used during upsampling\"\"\"\n",
    "        u = UpSampling2D(size=2)(layer_input)\n",
    "        u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "        if dropout_rate:\n",
    "            u = Dropout(dropout_rate)(u)\n",
    "        u = InstanceNormalization()(u)\n",
    "        u = Concatenate()([u, skip_input])\n",
    "        return u\n",
    "\n",
    "    # Image input\n",
    "    d0 = Input(shape=input_shape)\n",
    "\n",
    "    # Downsampling\n",
    "    d1 = conv2d(d0, gf)\n",
    "    d2 = conv2d(d1, gf*2)\n",
    "    d3 = conv2d(d2, gf*4)\n",
    "    d4 = conv2d(d3, gf*8)\n",
    "\n",
    "    # Upsampling\n",
    "    u1 = deconv2d(d4, d3, gf*4)\n",
    "    u2 = deconv2d(u1, d2, gf*2)\n",
    "    u3 = deconv2d(u2, d1, gf)\n",
    "\n",
    "    u4 = UpSampling2D(size=2)(u3)\n",
    "    output_img = Conv2D(n_C, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
    "\n",
    "    return Model(d0, output_img, name=name)\n",
    "\n",
    "def build_discriminator(input_shape, df, name):\n",
    "\n",
    "    def d_layer(layer_input, filters, f_size=4, normalization=True):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if normalization:\n",
    "            d = InstanceNormalization()(d)\n",
    "        return d\n",
    "\n",
    "    img = Input(shape=input_shape)\n",
    "\n",
    "    d1 = d_layer(img, df, normalization=False)\n",
    "    d2 = d_layer(d1, df*2)\n",
    "    d3 = d_layer(d2, df*4)\n",
    "    d4 = d_layer(d3, df*8)\n",
    "\n",
    "    validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "    return Model(img, validity, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, gf=32, df=64, name='cycleGAN_emoji'):\n",
    "    n_H, n_W, n_C = input_shape\n",
    "    # Calculate output shape of D (PatchGAN)\n",
    "    patch = int(n_H / 2**4)\n",
    "    disc_patch = (patch, patch, 1)\n",
    "    \n",
    "    # Build and compile the discriminators\n",
    "    d_A = build_discriminator(input_shape, df, name=\"d_A\")\n",
    "    d_B = build_discriminator(input_shape, df, name='d_B')\n",
    "    \n",
    "    #-------------------------\n",
    "    # Construct Computational\n",
    "    #   Graph of Generator\n",
    "    #-------------------------\n",
    "    # Build the generators\n",
    "    g_AB = build_generator(input_shape,gf,name='g_AB')\n",
    "    g_BA = build_generator(input_shape,gf,name='g_BA')\n",
    "    # Input images from both domains\n",
    "    img_A = Input(shape=input_shape,name='input_img_A')\n",
    "    img_B = Input(shape=input_shape,name='input_img_B')\n",
    "\n",
    "    # Translate images to the other domain\n",
    "    fake_B = g_AB(img_A)\n",
    "    fake_A = g_BA(img_B)\n",
    "    # Translate images back to original domain\n",
    "    reconstr_A = g_BA(fake_B)\n",
    "    reconstr_B = g_AB(fake_A)\n",
    "    # Identity mapping of images\n",
    "    img_A_id = g_BA(img_A)\n",
    "    img_B_id = g_AB(img_B)\n",
    "\n",
    "    # For the model model we will only train the generators\n",
    "    #NOTE: y setting trainable=False after the discriminator has been compiled \n",
    "    #the discriminator is still trained during discriminator.train_on_batch but \n",
    "    #since it's set to non-trainable before the model model is compiled it's not \n",
    "    #trained during model.train_on_batch.\n",
    "    #d_A.trainable = False\n",
    "    #d_B.trainable = False\n",
    "\n",
    "    # Discriminators determines validity of translated images\n",
    "    valid_A = d_A(fake_A)\n",
    "    valid_B = d_B(fake_B)\n",
    "\n",
    "    # Combined model trains generators to fool discriminators\n",
    "    model = Model(inputs=[img_A, img_B],\n",
    "                          outputs=[ valid_A, valid_B,\n",
    "                                    reconstr_A, reconstr_B,\n",
    "                                    img_A_id, img_B_id ],name=name)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,imgs_A, imgs_B, epochs=1, batch_size=1):\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    # Adversarial loss ground truths\n",
    "    m, n_H, n_W, n_C = imgs_A.shape\n",
    "    # Calculate output shape of D (PatchGAN)\n",
    "    patch = int(n_H / 2**4)\n",
    "    disc_patch = (patch, patch, 1)\n",
    "\n",
    "    valid = np.ones((m,) + disc_patch)\n",
    "    fake = np.zeros((m,) + disc_patch)\n",
    "    # ----------------------\n",
    "    #  Train Discriminators\n",
    "    # ----------------------\n",
    "    # Translate images to opposite domain\n",
    "    fake_B = model.get_layer(\"g_AB\").predict(imgs_A)\n",
    "    fake_A = model.get_layer(\"g_BA\").predict(imgs_B)\n",
    "    # Train the discriminators (original images = real / translated = Fake)\n",
    "    model.get_layer(\"g_AB\").trainable=False\n",
    "    model.get_layer(\"g_BA\").trainable=False\n",
    "    model.get_layer(\"d_A\").trainable=True\n",
    "    model.get_layer(\"d_B\").trainable=True\n",
    "    dA_loss_real = model.get_layer(\"d_A\").fit(imgs_A, valid, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    dA_loss_fake = model.get_layer(\"d_A\").fit(fake_A, fake, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "\n",
    "    dB_loss_real = model.get_layer(\"d_B\").fit(imgs_B, valid, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    dB_loss_fake = model.get_layer(\"d_B\").fit(fake_B, fake, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    # ------------------\n",
    "    #  Train Generators\n",
    "    # ------------------\n",
    "    # Train the generators\n",
    "    model.get_layer(\"g_AB\").trainable=True\n",
    "    model.get_layer(\"g_BA\").trainable=True\n",
    "    model.get_layer(\"d_A\").trainable=False\n",
    "    model.get_layer(\"d_B\").trainable=False\n",
    "    g_loss = model.fit([imgs_A, imgs_B],\n",
    "                                            [valid, valid,\n",
    "                                            imgs_A, imgs_B,\n",
    "                                            imgs_A, imgs_B],\n",
    "                                  batch_size=batch_size,\n",
    "                                  epochs=epochs)\n",
    "    \n",
    "    return model,g_loss,dA_loss_real,dA_loss_fake,dB_loss_real,dB_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(g_AB, g_BA, imgs_A, imgs_B,epoch):\n",
    "    m, n_H, n_W, _ = imgs_A.shape\n",
    "    figsize=(n_H,n_W)\n",
    "    # Translate images to the other domain\n",
    "    fake_B = g_AB.predict(imgs_A)\n",
    "    fake_A = g_BA.predict(imgs_B)\n",
    "    # Translate back to original domain\n",
    "    reconstr_A = g_BA.predict(fake_B)\n",
    "    reconstr_B = g_AB.predict(fake_A)\n",
    "    \n",
    "    titles = ['Original', 'Translated', 'Reconstructed']\n",
    "    fig, axs = plt.subplots(m, len(titles),figsize=figsize)\n",
    "    for r in range(m):\n",
    "        axs[r,0].imshow(imgs_A[r,:,:,0], cmap='gray')\n",
    "        axs[r,0].set_title(titles[0])\n",
    "        axs[r,0].axis('off')\n",
    "        axs[r,1].imshow(fake_B[r,:,:,0], cmap='gray')\n",
    "        axs[r,1].set_title(titles[1])\n",
    "        axs[r,1].axis('off')\n",
    "        axs[r,2].imshow(reconstr_A[r,:,:,0], cmap='gray')\n",
    "        axs[r,2].set_title(titles[2])\n",
    "        axs[r,2].axis('off')\n",
    "    fig.savefig(\"output/cycleGAN_epoch_%d.png\" % (epoch))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=[256,256,1]\n",
    "X,Y,n_x = load_images(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(model_filepath=None):\n",
    "    if model_filepath is None :\n",
    "        model=build_model(input_shape,name='model_combined')\n",
    "    else :\n",
    "        model = load_model(model_filepath)\n",
    "        \n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "    model.get_layer('d_A').compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "    model.get_layer('d_B').compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "\n",
    "    model.compile(loss=['mse', 'mse','mae', 'mae','mae', 'mae'],\n",
    "                loss_weights=[1, 1, 10.0, 10.0, 1.0, 1.0],\n",
    "                optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] saved_model/cycleGAN_emoji_model__epoch_last.h5 already exists - overwrite? [y/n]y\n",
      "[TIP] Next time specify overwrite=True!\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "model_filepath='saved_model/cycleGAN_emoji_model__epoch_last.h5'\n",
    "model=get_compiled_model()\n",
    "model.save(filepath=model_filepath,overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "m, _, _, _ = X.shape\n",
    "_s=np.random.randint(m-5)\n",
    "X_sample=X[_s:_s+5,:,:,:]\n",
    "Y_sample=Y[_s:_s+5,:,:,:]\n",
    "model = get_compiled_model(model_filepath)\n",
    "for i in range(0, 150):\n",
    "    model,_,_,_,_,_=train_epoch(model,X, Y, epochs=1, batch_size=16)\n",
    "    model.save(filepath=model_filepath,overwrite=True)\n",
    "    sample_images(model.get_layer('g_AB'),model.get_layer('g_BA'),X_sample, Y_sample,i)\n",
    "    model = get_compiled_model(model_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
